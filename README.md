# List of Papers

1. [Energy Efficient Architecture for Graph Analytics Accelerators](papers/Energy-Efficient-Architecture-for-Graph-Analytics-Accelerators)
2. [A Template Based Design Methodology for Graph Parallel Hardware Accelerators](papers/A-Template-Based-Design-Methodology-for-Graph-Parallel-Hardware-Accelerators)
3. [System Simulation with gem5 and SystemC](papers/System-Simulation-with-gem5-and-SystemC)
4. [GAIL: The Graph Algorithm Iron Law](papers/The-Graph-Algorithm-Iron-Law)
5. [Locality Exists in Graph Processing: Workload Characterization on an Ivy Bridge Serve](papers/Locality-Exists-In-Graph-Processing)
6. [Graphicionado A High Performance and Energy-Efficient Accelerator for Graph Analytics](papers/Graphicionado-A-High-Performance-and-Energy-Efficient-Accelerator-for-Graph-Analytics)
7. [Analysis and Optimization of the Memory Hierarchy for Graph Processing Workloads](papers/Analysis-and-Optimization-of-the-Memory-Hierarchy-for-Graph-Processing-Workloads)
8. [Alleviating Irregularity in Graph Analytics Acceleration: a Hardware/Software Design Approach](papers/Alleviating-Irregularity-in-Graph-Analytics-Acceleration)
9. [GNN Performance Optimization](papers/GNN-Performance-Optimization)
10. [Dissecting the Graphcore IPU Architecture](papers/Dissecting-the-Graphcore-IPU-Architecture)
11. [Using the Graphcore IPU for Traditional HPC Applications](papers/Using-the-Graphcore-IPU-for-Traditional-HPC-Applications)
12. [Roofline: An Insightful Visual Performance Model](papers/Roofline-An-Insightful-Visual-Performance-Model)
13. [CUDA New Features and Beyond](papers/CUDA-New-Features-and-Beyond)
14. [A Study of Persistent Threads Style GPU Programming for GPGPU Workloads](papers/A-Study-of-Persistent-Threads-Style-GPU-Programming-for-GPGPU-Workloads)
15. [BrainTorrent: A Peer to Peer Environment for Decentralized Federated Learning](papers/BrainTorrent-A-Peer-to-Peer-Environment-for-Decentralized-Federated-Learning)
16. [Whippletree: Task-based Scheduling of Dynamic Workloads on the GPU](papers/Whippletree:Task-based-Scheduling-of-Dynamic-Workloads-on-the-GPU)
17. [Groute: Asynchronous Multi-GPU Programming Model with Applications to Large-scale Graph Processing](papers/Groute:Asynchronous-Multi-GPU-Programming-Model-with-Applications-to-Large-scale-Graph-Processing)
18. [A Computational-Graph Partitioning Method for Training Memory-Constrained DNNs](papers/A-Computational-Graph-Partitioning-Method-for-Training-Memory-Constrained-DNNs)
19. [The Broker Queue: A Fast, Linearizable FIFO Queue for Fine-Granular Work Distribution on the GPU](papers/The-Broker-Queue-A-Fast-Linearizable-FIFO-Queue-for-Fine-Granular-Work-Distribution-on-the-GPU)
20. [Softshell: Dynamic Scheduling on GPUs](papers/Softshell-Dynamic-Scheduling-on-GPUs)
21. [Gravel: Fine-Grain GPU-Initiated Network Messages](papers/Gravel-Fine-Grain-GPU-Initiated-Network-Messages)
22. [SPIN:Seamless Operating System Integration of Peer to Peer DMA Between SSDs and GPUs](papers/SPIN-Seamless-Operating-System-Integration-of-Peer-to-Peer-DMA-Between-SSDs-and-GPUs)
23. [Automatic Graph Partitioning for Very Large-scale Deep Learning](papers/Automatic-Graph-Partitioning-for-Very-Large-scale-Deep-Learning)
24. [Stateful Dataflow Multigraphs: A data-centric
model for performance portability on heterogeneous architectures](papers/Stateful-Dataflow-Multigraphs-A-Data-Centric-Model-for-Performance-Portability-on-Heterogeneous-Architectures)
25. [Productivity, Portability, Performance: Data-Centric Python](papers/Productivity-Portability-Performance-Data-Centric-Python)
26. [Interferences between Communications and Computations in Distributed HPC Systems](papers/Interferences-between-Communications-and-Computations-in-Distributed-HPC-Systems)
27. [MVAPICH2-GPU: optimized GPU to GPU communication for InfiniBand clusters](papers/MVAPICH2-GPU-optimized-GPU-to-GPU-communication-for-InfiniBand-clusters)
28. [GGAS: Global GPU Address Spaces for Efficient Communication in Heterogeneous Clusters](papers/GGAS-Global-GPU-Address-Spaces-for-Efficient-Communication-in-Heterogeneous-Clusters)
29. [GPUnet: Networking Abstractions for GPU Programs](papers/GPUnet-Networking-Abstractions-for-GPU-Programs)
30. [GPUrdma: GPU-side library for high performance networking from GPU kernels](papers/GPUrdma-GPU-side-library-for-high-performance-networking-from-GPU-kernels)
31. [Trends in Data Locality Abstractions for HPC Systems](papers/Trends-in-Data-Locality-Abstractions-for-HPC-Systems)
32. [Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines](papers/Chimera-Efficiently-Training-Large-Scale-Neural-Networks-with-Bidirectional-Pipelines)
33. [Benchmarking GPUs to Tune Dense Linear Algebra](papers/Benchmarking-GPUs-to-Tune-Dense-Linear-Algebra)
34. [Brook for GPUs: stream computing on graphics hardware](papers/Brook-for-GPUs-stream-computing-on-graphics-hardware)
35. [IPUG: Accelerating Breadth-First Graph Traversals using Manycore Graphcore IPUs](papers/IPUG-Accelerating-Breadth-First-Graph-Traversals-using-Manycore-Graphcore-IPUs)
36. [Supporting RISC-V Performance Counters through Performance analysis tools for Linux](papers/Supporting-RISC-V-Performance-Counters-through-Performance-analysis-tools-for-Linux)
37. [Merrimac: Supercomputing with Streams](papers/Merrimac-Supercomputing-with-Streams)

## Two Papers A Week Goal (Starting from 28.06.2021)

### 28.06.2021 - 04.07.2021

* [Whippletree: Task-based Scheduling of Dynamic Workloads on the GPU](papers/Whippletree-Task-based-Scheduling-of-Dynamic-Workloads-on-the-GPU)
* [Groute: Asynchronous Multi-GPU Programming Model with Applications to Large-scale Graph Processing](papers/Groute-Asynchronous-Multi-GPU-Programming-Model-with-Applications-to-Large-scale-Graph-Processing)

### 05.07.2021 - 11.07.2021

* [A Computational-Graph Partitioning Method for Training Memory-Constrained DNNs](papers/A-Computational-Graph-Partitioning-Method-for-Training-Memory-Constrained-DNNs)
* [The Broker Queue: A Fast, Linearizable FIFO Queue for Fine-Granular Work Distribution on the GPU](papers/The-Broker-Queue-A-Fast-Linearizable-FIFO-Queue-for-Fine-Granular-Work-Distribution-on-the-GPU)

### 12.07.2021 - 18.07.2021

* [Softshell: Dynamic Scheduling on GPUs](papers/Softshell-Dynamic-Scheduling-on-GPUs)
* [Gravel: Fine-Grain GPU-Initiated Network Messages](papers/Gravel-Fine-Grain-GPU-Initiated-Network-Messages)

### 19.07.2021 - 08.08.2021

Unfortunately, my notes are on my tablet for this time period. I can't seem to find a time to pass them here (Translation: It's been a long time and I don't want to do it anymore :) ).

### 09.08.2021 - 15.08.2021

* [SPIN:Seamless Operating System Integration of Peer to Peer DMA Between SSDs and GPUs](papers/SPIN-Seamless-Operating-System-Integration-of-Peer-to-Peer-DMA-Between-SSDs-and-GPUs)
* [GPU-to-CPU Callbacks](papers/https://link.springer.com/content/pdf/10.1007%2F978-3-642-21878-1_45.pdf)

### 16.08.2021 - 22.08.2021

* [PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://arxiv.org/pdf/1912.01703.pdf) -> Zero technical depth. Please give my time back.
* [Automatic Graph Partitioning for Very Large-scale Deep Learning](papers/Automatic-Graph-Partitioning-for-Very-Large-scale-Deep-Learning)

### 23.08.2021 - 29.08.2021

* [Stateful Dataflow Multigraphs: A data-centric
model for performance portability on heterogeneous architectures](papers/Stateful-Dataflow-Multigraphs-A-Data-Centric-Model-for-Performance-Portability-on-Heterogeneous-Architectures)
* [Productivity, Portability, Performance: Data-Centric Python](papers/Productivity-Portability-Performance-Data-Centric-Python)

### 30.08.2021 - 05.09.2021

* [Analyzing Put/Get APIs for Thread-collaborative Processors](https://ieeexplore.ieee.org/document/7103479)
* [Analyzing Communication Models for Distributed Thread-Collaborative Processors in Terms of Energy and Time](https://ieeexplore.ieee.org/document/7095817)

### 06.09.2021 - 12.09.2021

* [Interferences between Communications and Computations in Distributed HPC Systems](papers/Interferences-between-Communications-and-Computations-in-Distributed-HPC-Systems)
* [Memory Bandwidth Contention: Communication vs Computation Tradeoffs in Supercomputers with Multicore Architectures](papers/Memory-Bandwidth-Contention-Communication-vs-Computation-Tradeoffs-in-Supercomputers-with-Multicore-Architectures)

### 13.09.2021 - 19.09.2021

* [MVAPICH2-GPU: optimized GPU to GPU communication for InfiniBand clusters](papers/MVAPICH2-GPU-optimized-GPU-to-GPU-communication-for-InfiniBand-clusters)
* [GGAS: Global GPU Address Spaces for Efficient Communication in Heterogeneous Clusters](papers/GGAS-Global-GPU-Address-Spaces-for-Efficient-Communication-in-Heterogeneous-Clusters)

### 20.09.2021 - 26.09.2021

* [GPUnet: Networking Abstractions for GPU Programs](papers/GPUnet-Networking-Abstractions-for-GPU-Programs)
* [GPUrdma: GPU-side library for high performance networking from GPU kernels](papers/GPUrdma-GPU-side-library-for-high-performance-networking-from-GPU-kernels)

### 27.09.2021 - 03.10.2021

* [Trends in Data Locality Abstractions for HPC Systems](papers/Trends-in-Data-Locality-Abstractions-for-HPC-Systems)
* [Moores Law is ending](https://ieeexplore.ieee.org/document/7368023)

### 04.10.2021 - 10.10.2021

* [Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines](papers/Chimera-Efficiently-Training-Large-Scale-Neural-Networks-with-Bidirectional-Pipelines)
* [Deep Residual Learning for Image Recognition](papers/Deep-Residual-Learning-for-Image-Recognition)

### 11.10.2021 - 17.10.2021

* [Benchmarking GPUs to Tune Dense Linear Algebra](papers/Benchmarking-GPUs-to-Tune-Dense-Linear-Algebra)
* [Brook for GPUs: stream computing on graphics hardware](papers/Brook-for-GPUs-stream-computing-on-graphics-hardware)

### 18.10.2021 - 24.10.2021

* [IPUG: Accelerating Breadth-First Graph Traversals using Manycore Graphcore IPUs](papers/IPUG-Accelerating-Breadth-First-Graph-Traversals-using-Manycore-Graphcore-IPUs)
* [Supporting RISC-V Performance Counters through Performance analysis tools for Linux](papers/Supporting-RISC-V-Performance-Counters-through-Performance-analysis-tools-for-Linux)
* [Merrimac: Supercomputing with Streams](papers/Merrimac-Supercomputing-with-Streams)

## Essential Reading List in Parallel Computing (Suggestions of my advisor (Didem Unat))

### Trends

* [Moores Law is ending](https://ieeexplore.ieee.org/document/7368023)
* [A new golden age for computer architecture](https://dl.acm.org/doi/10.1145/3282307)
* [Abstract machine models and proxy architectures for exascale computing](https://scholar.google.ch/citations?view_op=view_citation&hl=fr&user=NR70RpYAAAAJ&citation_for_view=NR70RpYAAAAJ:IjCSPb-OGe4C)  
* [Trends in Data Locality Abstractions for HPC Systems](https://ieeexplore.ieee.org/document/7924389)

### Architectures

* [Merrimac: Supercomputing with Streams](https://ieeexplore.ieee.org/document/1592938)
* [Synergistic Processing in Cell's Multicore Architecture](https://ieeexplore.ieee.org/document/1624323)
* [Knights Landing: Second Generation Intel Xeon Phi Product](https://ieeexplore.ieee.org/document/7453080)  

### Performance Models and Tools

* [Roofline: an insightful visual performance model for multicore architectures](https://dl.acm.org/doi/fullHtml/10.1145/1498765.1498785)
* [ExaSAT: An exascale co-design tool for performance modeling](https://journals.sagepub.com/doi/full/10.1177/1094342014568690)
* [hwloc: A generic framework for managing hardware affinities in HPC applications](https://ieeexplore.ieee.org/abstract/document/5452445?casa_token=mT7X-a9jAzoAAAAA:PLvrDSzj4Ek_Jsp3NQhNY8t7CCnP9EXCBwa2XsgFZUH-JZ3-sRWPrhdpemlxSUxiUKy94n-p2w)

### Applications 

* [Optimization of sparse matrix-vector multiplication on emerging multicore platforms](https://ieeexplore.ieee.org/abstract/document/5348797)
* [Stencil computation optimization and auto-tuning on state-of-the-art multicore architectures](https://ieeexplore.ieee.org/abstract/document/5222004)
* [Benchmarking GPUs to tune dense linear algebra](https://ieeexplore.ieee.org/document/5214359)

### Programming Models

* [Brook for GPUs: Stream Computing on Graphics Hardware](https://dl.acm.org/doi/10.1145/1015706.1015800)
* [OmpSs: A PROPOSAL FOR PROGRAMMING HETEROGENEOUS MULTI-CORE ARCHITECTURES](https://www.worldscientific.com/doi/abs/10.1142/S0129626411000151)
* [Productivity and performance using partitioned global address space languages](https://dl.acm.org/doi/10.1145/1278177.1278183)
* [Kokkos: Enabling manycore performance portability through polymorphic memory access patterns](https://www.osti.gov/servlets/purl/1106586)

### Compilers

* [Halide: A Language and Compiler for Optimizing Parallelism, Locality, and Recomputation in Image Processing Pipelines](https://people.csail.mit.edu/jrk/halide-pldi13.pdf)
* [Chill: A Framework for High Level Loop Transformations](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.214.8396&rep=rep1&type=pdf)
* [Pluto: A Practical and Automatic Polyhedral Program Optimization System](https://dl.acm.org/doi/10.1145/1375581.1375595)

### Runtime Systems 

* [Cilk: An Efficient Multithreaded Runtime System](http://supertech.csail.mit.edu/papers/PPoPP95.pdf)
* [StarPU: a unified platform for task scheduling on heterogeneous multicore architectures](https://hal.inria.fr/inria-00550877/document)
* [Legion: expressing locality and independence with logical regions](https://dl.acm.org/doi/10.5555/2388996.2389086)
* [Charm++ A portable concurrent object oriented system based on C++](https://dl.acm.org/doi/pdf/10.1145/165854.165874)

## GPU-NIC Interaction

Some approaches for GPU-NIC interaction. Useful for my research. 

### Coprocessor Model

Disallows GPUs to access NIC. You write CPU code for communication before and after a GPU kernel.

* [Efficient Inter-Node MPI Communication Using GPUDirect RDMA for InfiniBand Clusters with NVIDIA GPUs](https://ieeexplore.ieee.org/document/6687341) -> CUDA RDMA
* [Optimized GPU to GPU Communication for InfiniBand Clusters](https://link.springer.com/article/10.1007/s00450-011-0171-3) -> CUDA-aware MPI

### Message-per-lane Model

GPU threads independently access to NIC. 

* [GGAS: Global GPU Address Spaces for Efficient Communication in Heterogeneous Clusters](https://ieeexplore.ieee.org/document/6702638)
* [Simplifying Multi-GPU Communication with NVSHMEM](http://on-demand.gputechconf.com/gtc/2016/presentation/s6378-nathan-luehr-simplyfing-multi-gpu-communication-nvshmem.pdf) -> Not a paper but good to read.

### Coalesced APIs

Threads coordinate to access the NIC.

* [GPUnet: Networking Abstractions for GPU Programs](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-kim.pdf)
* [GPUrdma: GPU-Side Library for High Performance Networking from GPU Kernels](https://dl.acm.org/doi/10.1145/2931088.2931091)
